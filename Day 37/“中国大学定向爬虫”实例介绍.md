### 第十八天
# “中国大学排名定向爬虫教学” 介绍

功能描述:
- 输入： 大学排名 URL 链接
- 输出： 大学排名信息的屏幕输出（排名， 大学名称，总分）
- 技术路线： requests-bs4
  
我们要实现的爬虫是一个定向爬虫，那么什么是定向爬虫？
- 定向爬虫： 仅对输入 URL 进行爬取， 不扩展爬取

我们还有测试这一个定向爬虫的可行性，那就是要确定该网页的信息是写在 HTML 代码中的，如果该网页的信息是用 JavaScript 等脚本语言生成的动态信息的话， 使用 requests 库来爬取就有点心有余而力不足了 XD

我们还有看一下该网站是否提供了 robots 协议，如果有的话我们就要遵守哦！（但是最好大学网并没有 robots 协议，所以就不用遵守咯 XD）

---
## 程序的结构设计
- 步骤一： 从网络上获得大学排名网页内容
- 步骤二： 提取网页内容的信息到合适的数据结构
- 步骤三： 利用数据结构展示并输出结果
---
## 程序的结构设计（定义函数）
- 步骤一： 从网路上获得大学排名网页的信息 getHTMLText()
- 步骤二： 提取网页中的信息到合适的数据结构 fillUnivList()
- 步骤三： 利用数据结构展示并输出结果 printUnivList()
---
# “中国大学排名定向爬虫教学” 实列编写
先 import 需要的库 XD
```
import requests
from bs4 import BeautifulSoup
import bs4
```

将基本的代码框架写出来
```
def getHTMLText(url):
    return ' '

def fillUnivList(ulist, html):
    pass

def printUnivList(ulist, num):
    print('Suc' + str(num))
```

接着完善 getHTMLText 函数
```
# 获得最好大学网的 HTML 源代码
def getHTMLText(url):
    try:
        r = requests.get(url, timeout = 50) # timeout = 50 代表说最久的连接时限是 50 秒
        r.raise_for_status
        r.encoding = r.apparent_encoding
        return r.text 
    except:
        return ' '
```

fillUnivList 函数
```
# 将获得的源代码储存进一个名为 ulist列表里
def fillUnivList(ulist, html):
    soup = BeautifulSoup(html, 'html.parser')
    for tr in soup.find('tbody').children:
        if isinstance(tr, bs4.element.Tag):
            tds = tr('td')
            ulist.append([tds[0].string, tds[1].string, tds[2].string])
```

printUnivList 函数
```
# 将 ulist 的内容打印出来，这里的 num 是要打印列表里多少个元素
def printUnivList(ulist, num):
    print('{:^10}\t{:^6}\t{:^10}'.format('排名', '学校名称', '总分'))
    for i in range(num):
        u = ulist[i]
        print('{:^10}\t{:^6}\t{:^10}'.format(u[0], u[1], u[2]))
```

接着是 main 函数
```
def main():
    uinfo = []
    url = 'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html'
    html = getHTMLText(url)
    fillUnivList(uinfo, html)
    printUnivList(uinfo, 20) # 首 20 个大学

main()
```
